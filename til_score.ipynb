{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from tiatoolbox.wsicore.wsireader import VirtualWSIReader, WSIReader\n",
    "from tiatoolbox.tools.patchextraction import get_patch_extractor\n",
    "from tissue_masker_lite import get_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tiatoolbox.models.engine.semantic_segmentor import SemanticSegmentor\n",
    "import segmentation_models_pytorch as smp\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import pickle\n",
    "import skimage\n",
    "import cv2\n",
    "import skimage.measure\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from tiatoolbox.annotation.storage import Annotation, SQLiteStore\n",
    "from shapely import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_name = \"106S.tif\"\n",
    "wsi_without_ext = os.path.splitext(wsi_name)[0]\n",
    "masks_dir = \"/home/u1910100/GitHub/TIAger-Torch/output/seg_out\"\n",
    "tumor_stroma_mask_path = os.path.join(masks_dir, f\"{wsi_without_ext}_tumor_stroma.npy\")\n",
    "\n",
    "tumor_stroma_mask = np.load(tumor_stroma_mask_path)\n",
    "\n",
    "plt.imshow(tumor_stroma_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detModel1 = \"/home/u1910100/GitHub/TIAger-Torch/runs/cell/fold_1/model_55.pth\"\n",
    "detModel2 = \"/home/u1910100/GitHub/TIAger-Torch/runs/cell/fold_2/model_40.pth\"\n",
    "detModel3 = \"/home/u1910100/GitHub/TIAger-Torch/runs/cell/fold_3/model_30.pth\"\n",
    "detModel = [detModel1, detModel2, detModel3]\n",
    "\n",
    "models: list[torch.nn.Module] = []\n",
    "for model_path in detModel:\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"efficientnet-b0\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "        encoder_weights=None,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "        in_channels=3,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "        classes=1,  # model output channels (number of classes in your dataset)\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenet_normalise(img: torch.tensor) -> torch.tensor:\n",
    "    \"\"\"Normalises input image to ImageNet mean and std\"\"\"\n",
    "\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "    for i in range(3):\n",
    "        img[:, i, :, :] = (img[:, i, :, :] - mean[i]) / std[i]\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def mm2_to_px(mm2, mpp):\n",
    "    return (mm2 * 1e6) / mpp**2\n",
    "\n",
    "\n",
    "def dist_to_px(dist, mpp):\n",
    "    dist_px = int(round(dist / mpp))\n",
    "    return dist_px\n",
    "\n",
    "\n",
    "def px_to_mm(px, mpp):\n",
    "    return px * mpp / 1000\n",
    "\n",
    "\n",
    "def px_to_um2(px, mpp):\n",
    "    area_um2 = px * (mpp**2)\n",
    "    return area_um2\n",
    "\n",
    "\n",
    "def detections_in_tile(image_tile, det_models):\n",
    "    patch_size = 128\n",
    "    overlap = 28\n",
    "    tile_reader = VirtualWSIReader(image_tile, power=20)\n",
    "\n",
    "    patch_extractor = get_patch_extractor(\n",
    "        input_img=tile_reader,\n",
    "        method_name=\"slidingwindow\",\n",
    "        patch_size=(patch_size, patch_size),\n",
    "        stride=(overlap, overlap),\n",
    "        resolution=20,\n",
    "        units=\"power\",\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    batch_size = 256\n",
    "\n",
    "    dataloader = DataLoader(patch_extractor, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for i, imgs in enumerate(tqdm(dataloader, leave=False)):\n",
    "        imgs = torch.permute(imgs, (0, 3, 1, 2))\n",
    "        imgs = imgs / 255\n",
    "        imgs = imagenet_normalise(imgs)\n",
    "        imgs = imgs.to(\"cuda\").float()\n",
    "\n",
    "        val_predicts = np.zeros(shape=(imgs.size()[0], 128, 128), dtype=np.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for det_model in det_models:\n",
    "                temp_out = det_model(imgs)\n",
    "                temp_out = torch.sigmoid(temp_out)\n",
    "                temp_out = temp_out.detach().cpu().numpy()[:, 0, :, :]\n",
    "\n",
    "                val_predicts += temp_out\n",
    "\n",
    "        val_predicts = val_predicts / 3\n",
    "        predictions.extend(list(val_predicts))\n",
    "\n",
    "    return predictions, patch_extractor.coordinate_list\n",
    "\n",
    "\n",
    "def tile_detection_stats(predictions, coordinate_list, x, y):\n",
    "    tile_prediction = SemanticSegmentor.merge_prediction(\n",
    "        (1024, 1024), predictions, coordinate_list\n",
    "    )\n",
    "    threshold = 0.99\n",
    "    tile_prediction_mask = tile_prediction > threshold\n",
    "\n",
    "    mask_label = skimage.measure.label(tile_prediction_mask)\n",
    "\n",
    "    stats = skimage.measure.regionprops(mask_label, intensity_image=tile_prediction)\n",
    "    output_points = []\n",
    "    annotations = []\n",
    "    for region in stats:\n",
    "        centroid = np.round(region[\"centroid\"]).astype(int)\n",
    "\n",
    "        c, r, confidence = (\n",
    "            np.round(centroid[1]),\n",
    "            np.round(centroid[0]),\n",
    "            region[\"mean_intensity\"],\n",
    "        )\n",
    "\n",
    "        c1 = c + x\n",
    "        r1 = r + y\n",
    "        prediction_record = {\n",
    "            \"point\": [\n",
    "                float(px_to_mm(c1, 0.5)),\n",
    "                float(px_to_mm(r1, 0.5)),\n",
    "                float(0.5009999871253967),\n",
    "            ],\n",
    "            \"probability\": float(confidence),\n",
    "        }\n",
    "\n",
    "        output_points.append(prediction_record)\n",
    "        annotations.append((int(c1), int(r1)))\n",
    "    return annotations, output_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_dir = \"/home/u1910100/Documents/Tiger_Data/wsitils/images/\"\n",
    "wsi_path = os.path.join(wsi_dir, wsi_name)\n",
    "wsi = WSIReader.open(wsi_path)\n",
    "\n",
    "tile_extractor = get_patch_extractor(\n",
    "    input_img=wsi,\n",
    "    method_name=\"slidingwindow\",\n",
    "    patch_size=(1024, 1024),\n",
    "    resolution=20,\n",
    "    units=\"power\",\n",
    "    input_mask=tumor_stroma_mask,\n",
    ")\n",
    "# Each tile of size 1024x1024\n",
    "annotations = []\n",
    "output_dict = {\n",
    "    \"type\": \"Multiple points\",\n",
    "    \"version\": {\"major\": 1, \"minor\": 0},\n",
    "    \"points\": [],\n",
    "}\n",
    "\n",
    "for i, tile in enumerate(tqdm(tile_extractor)):\n",
    "    bounding_box = tile_extractor.coordinate_list[i]  # (x_start, y_start, x_end, y_end)\n",
    "    predictions, coordinates = detections_in_tile(tile, models)\n",
    "    annotations_tile, output_points_tile = tile_detection_stats(\n",
    "        predictions, coordinates, bounding_box[0], bounding_box[1]\n",
    "    )\n",
    "    annotations.extend(annotations_tile)\n",
    "    output_dict[\"points\"].extend(output_points_tile)\n",
    "\n",
    "output_path = (\n",
    "    f\"/home/u1910100/GitHub/TIAger-Torch/output/det_out/{wsi_without_ext}.json\"\n",
    ")\n",
    "with open(output_path, \"w\") as fp:\n",
    "    json.dump(output_dict, fp, indent=4)\n",
    "\n",
    "output_path = (\n",
    "    f\"/home/u1910100/GitHub/TIAger-Torch/output/det_out/{wsi_without_ext}_points.json\"\n",
    ")\n",
    "with open(output_path, \"w\") as fp:\n",
    "    json.dump(annotations, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_box(x, y, size):\n",
    "    \"\"\"Convert centerpoint to bounding box of fixed size\"\"\"\n",
    "    return np.array([x - size, y - size, x + size, y + size])\n",
    "\n",
    "\n",
    "def get_centerpoints(box, dist):\n",
    "    \"\"\"Returns centerpoints of box\"\"\"\n",
    "    return (box[0] + dist, box[1] + dist)\n",
    "\n",
    "\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    \"\"\"Very efficient NMS function taken from pyimagesearch\"\"\"\n",
    "\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(\n",
    "            idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0]))\n",
    "        )\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "\n",
    "def slide_nms(slide_path, annotation_path, tile_size):\n",
    "    \"\"\"Iterate over WholeSlideAnnotation and perform NMS. For this to properly work, tiles need to be larger than model inference patches.\"\"\"\n",
    "    # Open WSI and detection points file\n",
    "    wsi = WSIReader.open(slide_path)\n",
    "    with open(annotation_path, \"r\") as fp:\n",
    "        cell_points = json.load(fp)\n",
    "    print(f\"{len(cell_points)} before nms\")\n",
    "    store = points_to_annotation_store(cell_points)\n",
    "    # Get base line WSI size\n",
    "    shape = wsi.slide_dimensions(resolution=0, units=\"level\")\n",
    "\n",
    "    center_nms_points = []\n",
    "\n",
    "    box_size = 8\n",
    "    # get 2048x2048 patch coordinates without overlap\n",
    "    for y_pos in range(0, shape[1], tile_size):\n",
    "        for x_pos in range(0, shape[0], tile_size):\n",
    "            # Select annotations within 2048x2048 box\n",
    "            box = [x_pos, y_pos, x_pos + tile_size, y_pos + tile_size]\n",
    "            patch_points = get_points_within_box(store, box)\n",
    "\n",
    "            if len(patch_points) < 2:\n",
    "                continue\n",
    "\n",
    "            # Convert each point to a 8x8 box\n",
    "            boxes = np.array([point_to_box(x[0], x[1], box_size) for x in patch_points])\n",
    "            nms_boxes = non_max_suppression_fast(boxes, 0.7)\n",
    "            for box in nms_boxes:\n",
    "                center_nms_points.append(get_centerpoints(box, box_size))\n",
    "    return center_nms_points\n",
    "\n",
    "\n",
    "def points_to_annotation_store(points: list):\n",
    "    \"\"\"\n",
    "    Args: points(list): list of (x,y) coordinates\n",
    "    \"\"\"\n",
    "    annotation_store = SQLiteStore()\n",
    "\n",
    "    for coord in points:\n",
    "        annotation_store.append(\n",
    "            Annotation(geometry=Point(coord[0], coord[1]), properties={\"class\": 1})\n",
    "        )\n",
    "\n",
    "    return annotation_store\n",
    "\n",
    "\n",
    "def get_points_within_box(annotation_store, box):\n",
    "    query_poly = Polygon.from_bounds(box[0], box[1], box[2], box[3])\n",
    "    anns = annotation_store.query(geometry=query_poly)\n",
    "    results = []\n",
    "    for point in anns.items():\n",
    "        results.append(point[1].coords[0])\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_mask_area(mask_path):\n",
    "    \"\"\"Get the size of a mask in pixels where the mask is 1.\"\"\"\n",
    "\n",
    "    mask = np.load(mask_path)\n",
    "    counts = np.count_nonzero(mask)\n",
    "    down = 6\n",
    "    area = counts * down**2\n",
    "    return area\n",
    "\n",
    "\n",
    "def create_til_score(wsi_path, cell_points_path, tumor_stroma_mask_path):\n",
    "    nms_points = slide_nms(\n",
    "        slide_path=wsi_path, annotation_path=cell_points_path, tile_size=2048\n",
    "    )\n",
    "\n",
    "    cell_counts = len(nms_points)\n",
    "    print(f\"TIL counts = {cell_counts}\")\n",
    "\n",
    "    til_area = dist_to_px(4, 0.5) ** 2\n",
    "    tils_area = cell_counts * til_area\n",
    "\n",
    "    stroma_area = get_mask_area(tumor_stroma_mask_path)\n",
    "    print(f\"stroma area = {stroma_area}\")\n",
    "    tilscore = int((100 / int(stroma_area)) * int(tils_area))\n",
    "    tilscore = min(100, tilscore)\n",
    "    tilscore = max(0, tilscore)\n",
    "    print(f\"tilscore = {tilscore}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_without_ext = \"106S\"\n",
    "cell_points_dir = \"/home/u1910100/GitHub/TIAger-Torch/output/det_out\"\n",
    "cell_points_path = os.path.join(cell_points_dir, f\"{wsi_without_ext}_points.json\")\n",
    "wsi_dir = \"/home/u1910100/Documents/Tiger_Data/wsitils/images/\"\n",
    "wsi_path = os.path.join(wsi_dir, f\"{wsi_without_ext}.tif\")\n",
    "masks_dir = \"/home/u1910100/GitHub/TIAger-Torch/output/seg_out\"\n",
    "tumor_stroma_mask_path = os.path.join(masks_dir, f\"{wsi_without_ext}_tumor_stroma.npy\")\n",
    "\n",
    "create_til_score(wsi_path, cell_points_path, tumor_stroma_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_points_dir = \"/home/u1910100/GitHub/TIAger-Torch/output/det_out\"\n",
    "cell_points_path = os.path.join(cell_points_dir, f\"{wsi_without_ext}_points.json\")\n",
    "wsi_name = \"106S.tif\"\n",
    "wsi_without_ext = os.path.splitext(wsi_name)[0]\n",
    "wsi_dir = \"/home/u1910100/Documents/Tiger_Data/wsitils/images/\"\n",
    "wsi_path = os.path.join(wsi_dir, wsi_name)\n",
    "\n",
    "\n",
    "with open(cell_points_path, \"r\") as fp:\n",
    "    cell_points = json.load(fp)\n",
    "print(len(cell_points))\n",
    "\n",
    "new_points = slide_nms(\n",
    "    slide_path=wsi_path, annotation_path=cell_points_path, tile_size=2048\n",
    ")\n",
    "print(len(new_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIAToolBox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
