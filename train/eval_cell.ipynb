{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_cell_dataloaders\n",
    "import torch\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "import numpy as np\n",
    "import os\n",
    "from train import train_model\n",
    "from loss_functions import BCE_Dice_Loss\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "import cv2\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD_DIR = \"/media/u1910100/Extreme SSD/data/tiger/cell_detection/dilation/patches/128\"\n",
    "\n",
    "test_fold = 5\n",
    "print(f\"Testing using fold {test_fold}\")\n",
    "train_loader, test_loader = get_cell_dataloaders(\n",
    "    FOLD_DIR, fold_num=test_fold, batch_size=1, phase=\"Test\"\n",
    ")\n",
    "\n",
    "print(len(test_loader.sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagenet_denormalise(img):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img_normal = (img * std) + mean\n",
    "    return img_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b0\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=None,  # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,  # model output channels (number of classes in your dataset)\n",
    ")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\"/home/u1910100/GitHub/TIAger-Torch/runs/cell/weights_v2/cell_5.pth\")\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    sum_IOU = []\n",
    "    sum_F1 = []\n",
    "    sum_precison = []\n",
    "    sum_recall = []\n",
    "    print(f\"threshold = {threshold}\")\n",
    "    # for i in range(0,5):\n",
    "    for batch in tqdm(test_loader):\n",
    "        batch = next(iter(test_loader))\n",
    "        imgs, masks = batch[\"img\"], batch[\"mask\"]\n",
    "\n",
    "        # img = batch[\"img\"][0].numpy(force=True)\n",
    "        # img = np.moveaxis(img, 0, 2)\n",
    "        # img_normal = imagenet_denormalise(img)\n",
    "        # fig, axs = plt.subplots(1, 3)\n",
    "        # axs[0].imshow(img_normal)\n",
    "        # axs[0].title.set_text(\"Image\")\n",
    "        # axs[1].imshow(masks[0][0], cmap='gray')\n",
    "        # axs[1].title.set_text(\"Ground Truth\")\n",
    "\n",
    "        imgs = imgs.to(\"cuda\").float()\n",
    "        masks = masks.to(\"cuda\").long()\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs)\n",
    "            out = torch.sigmoid(out)\n",
    "\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(\n",
    "            out, masks, mode=\"binary\", threshold=threshold\n",
    "        )\n",
    "        iou_score = smp.metrics.iou_score(\n",
    "            tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "        )\n",
    "        f1_score = smp.metrics.f1_score(\n",
    "            tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "        )\n",
    "        precison_score = smp.metrics.precision(\n",
    "            tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "        )\n",
    "        recall_score = smp.metrics.recall(\n",
    "            tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "        )\n",
    "\n",
    "        iou_score = iou_score.cpu().detach().item()\n",
    "        f1_score = f1_score.cpu().detach().item()\n",
    "        precison_score = precison_score.cpu().detach().item()\n",
    "        recall_score = recall_score.cpu().detach().item()\n",
    "\n",
    "        if math.isnan(iou_score):\n",
    "            iou_score = 1\n",
    "        if math.isnan(f1_score):\n",
    "            f1_score = 1\n",
    "        if math.isnan(precison_score):\n",
    "            precison_score = 1\n",
    "        if math.isnan(recall_score):\n",
    "            recall_score = 1\n",
    "\n",
    "        # out = out.cpu().detach().numpy()[0][0]\n",
    "        # out_mask = np.where(out >= threshold, 1, 0).astype(np.uint8)\n",
    "        # axs[2].imshow(out_mask, cmap=\"gray\")\n",
    "        # axs[2].title.set_text(\"Prediction\")\n",
    "        # for ax in fig.axes:\n",
    "        #     ax.axis(\"off\")\n",
    "        # plt.show()\n",
    "        # print(f\"IOU (Jaccard): {iou_score}\")\n",
    "        # print(f\"F1 (Dice): {f1_score}\")\n",
    "\n",
    "        sum_IOU.append(iou_score)\n",
    "        sum_F1.append(f1_score)\n",
    "        sum_precison.append(precison_score)\n",
    "        sum_recall.append(recall_score)\n",
    "\n",
    "    # sum_IOU = np.array(sum_IOU)\n",
    "    # sum_F1 = np.array(sum_F1)\n",
    "    print(\"-------------\")\n",
    "    print(\"Avg Jaccard \", np.mean(sum_IOU))\n",
    "    print(\"Avg Dice \", np.mean(sum_F1))\n",
    "    print(\"Avg Precision \", np.mean(sum_precison))\n",
    "    print(\"Avg Recall \", np.mean(sum_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_centers(cell_mask):\n",
    "    mask_label = skimage.measure.label(cell_mask)\n",
    "    stats = skimage.measure.regionprops(mask_label)\n",
    "    centers = []\n",
    "    for region in stats:\n",
    "        centroid = region[\"centroid\"]\n",
    "        centers.append(centroid)\n",
    "    return centers\n",
    "\n",
    "\n",
    "def point_to_box(x, y, size):\n",
    "    \"\"\"Convert centerpoint to bounding box of fixed size\"\"\"\n",
    "    return np.array([x - size, y - size, x + size, y + size])\n",
    "\n",
    "\n",
    "def check_point_in_box(x, y, box):\n",
    "    cond_1 = x >= box[0] and x <= box[2]\n",
    "    cond_2 = y >= box[1] and y <= box[3]\n",
    "    return cond_1 and cond_2\n",
    "\n",
    "\n",
    "def check_point_in_circle(x, y, center_x, center_y, radius):\n",
    "    dist = math.sqrt((center_x - x) ** 2 + (center_y - y) ** 2)\n",
    "    # print(dist)\n",
    "    return dist <= radius\n",
    "\n",
    "\n",
    "def evaluate_cell_predictions(gt_centers, pred_centers):\n",
    "    tp_x_coords = []\n",
    "    tp_y_coords = []\n",
    "\n",
    "    # print(f\"Total gt cells: {len(gt_centers)}\")\n",
    "    # print(f\"Total pred cells: {len(pred_centers)}\")\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for j, pred_center in enumerate(pred_centers):\n",
    "        for i, true_center in enumerate(gt_centers):\n",
    "            # true_box = point_to_box(true_center[0], true_center[1], 8)\n",
    "            # if check_point_in_box(pred_center[0], pred_center[1], true_box):\n",
    "            if check_point_in_circle(\n",
    "                pred_center[0], pred_center[1], true_center[0], true_center[1], 8\n",
    "            ):\n",
    "                tp_x_coords.append(pred_center[0])\n",
    "                tp_y_coords.append(pred_center[1])\n",
    "                tp += 1\n",
    "                del gt_centers[i]\n",
    "                del pred_centers[j]\n",
    "\n",
    "    for i, true_center in enumerate(gt_centers):\n",
    "        for j, pred_center in enumerate(pred_centers):\n",
    "            # true_box = point_to_box(true_center[0], true_center[1], 8)\n",
    "            # if check_point_in_box(pred_center[0], pred_center[1], true_box):\n",
    "            if check_point_in_circle(\n",
    "                pred_center[0], pred_center[1], true_center[0], true_center[1], 8\n",
    "            ):\n",
    "                tp_x_coords.append(pred_center[0])\n",
    "                tp_y_coords.append(pred_center[1])\n",
    "                tp += 1\n",
    "                del gt_centers[i]\n",
    "                del pred_centers[j]\n",
    "\n",
    "    fn = len(gt_centers)\n",
    "    fp = len(pred_centers)\n",
    "\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 1\n",
    "    try:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 1\n",
    "\n",
    "    # print(f\"True Positives: {tp}\")\n",
    "    # print(f\"False Positives: {fp}\")\n",
    "    # print(f\"False Negatives: {fn}\")\n",
    "    # print(f\"f1 = {f1}\")\n",
    "    # print(f\"precision = {precision}\")\n",
    "    # print(f\"recall = {recall}\")\n",
    "\n",
    "    return tp_x_coords, tp_y_coords, f1, precision, recall\n",
    "\n",
    "\n",
    "def erode_mask(mask):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3692/3692 [00:50<00:00, 72.67it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Avg F1  0.758339078511378\n",
      "Avg Precision  0.823269408849183\n",
      "Avg Recall  0.871468628595211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sum_IOU = []\n",
    "sum_F1 = []\n",
    "sum_precison = []\n",
    "sum_recall = []\n",
    "sum_Dice = []\n",
    "threshold = 0.5\n",
    "print(f\"threshold = {threshold}\")\n",
    "\n",
    "for batch in tqdm(test_loader):\n",
    "    # for i in range(0, 1):\n",
    "    batch = next(iter(test_loader))\n",
    "    imgs, masks = batch[\"img\"], batch[\"mask\"]\n",
    "\n",
    "    # img = batch[\"img\"][0].numpy(force=True)\n",
    "    # img = np.moveaxis(img, 0, 2)\n",
    "    # img_normal = imagenet_denormalise(img)\n",
    "    # fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    # axs[0].imshow(img_normal)\n",
    "    # axs[0].title.set_text(\"Image\")\n",
    "    # axs[1].imshow(masks[0][0], cmap=\"gray\")\n",
    "    # axs[1].title.set_text(\"Ground Truth\")\n",
    "\n",
    "    imgs = imgs.to(\"cuda\").float()\n",
    "    masks = masks.to(\"cuda\").long()\n",
    "    with torch.no_grad():\n",
    "        out = model(imgs)\n",
    "        out = torch.nn.functional.sigmoid(out)\n",
    "\n",
    "    tp, fp, fn, tn = smp.metrics.get_stats(\n",
    "        out, masks, mode=\"binary\", threshold=threshold\n",
    "    )\n",
    "    iou_score = smp.metrics.iou_score(\n",
    "        tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "    )\n",
    "    f1_score = smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\", zero_division=0)\n",
    "    precison_score = smp.metrics.precision(\n",
    "        tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "    )\n",
    "    recall_score = smp.metrics.recall(\n",
    "        tp, fp, fn, tn, reduction=\"micro\", zero_division=1\n",
    "    )\n",
    "\n",
    "    iou_score = iou_score.cpu().detach().item()\n",
    "    f1_score = f1_score.cpu().detach().item()\n",
    "    precison_score = precison_score.cpu().detach().item()\n",
    "    recall_score = recall_score.cpu().detach().item()\n",
    "\n",
    "    if math.isnan(iou_score):\n",
    "        iou_score = 1\n",
    "    if math.isnan(f1_score):\n",
    "        f1_score = 1\n",
    "    if math.isnan(precison_score):\n",
    "        precison_score = 1\n",
    "    if math.isnan(recall_score):\n",
    "        recall_score = 1\n",
    "\n",
    "    out = out.cpu().detach().numpy()\n",
    "    out_mask = out[0][0]\n",
    "\n",
    "    out_mask[out_mask >= threshold] = 1\n",
    "    out_mask[out_mask < threshold] = 0\n",
    "\n",
    "    pred_centers = get_cell_centers(out_mask)\n",
    "    masks = masks.cpu().detach().numpy()[0][0].astype(np.uint8)\n",
    "    true_centers = get_cell_centers(masks)\n",
    "    xs, ys, f1, precision, recall = evaluate_cell_predictions(\n",
    "        true_centers, pred_centers\n",
    "    )\n",
    "\n",
    "    # axs[2].imshow(out_mask, cmap=\"gray\")\n",
    "    # axs[2].title.set_text(\"Prediction\")\n",
    "\n",
    "    # axs[0].scatter(ys, xs, alpha=0.5)\n",
    "    # axs[1].scatter(ys, xs, alpha=0.5)\n",
    "    # axs[2].scatter(ys, xs, alpha=0.5)\n",
    "\n",
    "    # for ax in fig.axes:\n",
    "    #     ax.axis(\"off\")\n",
    "    # plt.show()\n",
    "\n",
    "    # print(f\"IOU (Jaccard): {iou_score}\")\n",
    "    # print(f\"F1 (Dice): {f1_score}\")\n",
    "    sum_Dice.append(f1_score)\n",
    "    sum_IOU.append(iou_score)\n",
    "    sum_F1.append(f1)\n",
    "    sum_precison.append(precision)\n",
    "    sum_recall.append(recall)\n",
    "\n",
    "# sum_IOU = np.array(sum_IOU)\n",
    "# sum_F1 = np.array(sum_F1)\n",
    "print(\"-------------\")\n",
    "# print(\"Avg Jaccard \", np.mean(sum_IOU))\n",
    "# print(\"Avg Dice \", np.mean(sum_Dice))\n",
    "print(\"Avg F1 \", np.mean(sum_F1))\n",
    "print(\"Avg Precision \", np.mean(sum_precison))\n",
    "print(\"Avg Recall \", np.mean(sum_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIAToolBox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
